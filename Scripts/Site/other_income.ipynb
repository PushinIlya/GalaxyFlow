{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44df2cbf",
   "metadata": {},
   "source": [
    "## Формирование отчёта о финансовых результатах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cc8bcf",
   "metadata": {},
   "source": [
    "### Расчёт \"Прочие доходы\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3d4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Скрипт для преобразования исходных данных из 1C\n",
    "'''\n",
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0075ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем путь к папке с исходными данными в переменную\n",
    "source = pathlib.Path(os.getcwd().replace('Fin_Flow', os.path.join('YandexDisk', 'Fin_Flow')).replace('Scripts', 'Source data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7236c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим списки с названиями всех необходимых файлов в папке с исходными данными\n",
    "source_oth_incom_name = [raw_data for raw_data in os.listdir(source) if 'Прочие доходы' in raw_data and\n",
    "                         raw_data.endswith('.xlsx')]\n",
    "\n",
    "print(source_oth_incom_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим excel-файлы в pandas\n",
    "oth_incom = {raw_data: pd.read_excel(os.path.join(source, f'{raw_data}'), header=None) for raw_data in source_oth_incom_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим excel-файлы в openpyxl\n",
    "oth_incom_structure = {raw_data: load_workbook(filename=os.path.join(source, f'{raw_data}')) for raw_data in source_oth_incom_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получим первый лист в каждом excel-файле\n",
    "oth_incom_structure = {i[0]: i[1].worksheets[0] for i in oth_incom_structure.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь для каждого файла, где ключ-номер строки, а значение-уровень группировки\n",
    "oth_incom_structure = {i[0]: {row: i[1].row_dimensions[row].outline_level for row in i[1].row_dimensions} for i in oth_incom_structure.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем словари в pd.Series\n",
    "oth_incom_structure = {i[0]: pd.Series(i[1], name='Уровень').reset_index(drop=True) for i in oth_incom_structure.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72136d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим в основные датафреймы уровни группировки строк\n",
    "oth_incom = {i[0]: i[1].merge(oth_incom_structure[i[0]], left_index=True, right_index=True, how='inner') for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eaa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].drop(list(range(6))) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Организация'] = i.apply(lambda row: row[0] if row['Уровень'] == 0 else np.nan,\n",
    "                               axis=1)\n",
    "    i['Счет'] = i.apply(lambda row: row[0] if row['Уровень'] == 1 else np.nan,\n",
    "                        axis=1)\n",
    "    i['Кор_счет'] = i.apply(lambda row: row[0] if row['Уровень'] == 2 else np.nan,\n",
    "                            axis=1)\n",
    "    i['Вид статьи'] = i.apply(lambda row: row[0] if row['Уровень'] == 3 else np.nan,\n",
    "                              axis=1)\n",
    "    i['Статья'] = i.apply(lambda row: row[0] if row['Уровень'] == 4 else np.nan,\n",
    "                          axis=1)\n",
    "    i['Дата'] = i.apply(lambda row: row[0] if row['Уровень'] == 5 else np.nan,\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e48263",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].rename(columns={1: 'Изменение'}) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словари с именами столбцов и типами данных\n",
    "type_of_columns_oth_incom = {'Изменение': 'float64',\n",
    "                             'Организация': 'object',\n",
    "                             'Счет': 'object',\n",
    "                             'Кор_счет': 'object', \n",
    "                             'Вид статьи': 'object',\n",
    "                             'Статья': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим строки для преобразования их в числовые значения\n",
    "for i in oth_incom.values():\n",
    "    i['Изменение'] = i['Изменение'].apply(lambda row: str(row).replace(',', '.').replace(' ', '')\n",
    "                                          if pd.notna(row)\n",
    "                                          else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменим тип данных в каждом датафрейме в соответствии со словарём 'type_of_columns'\n",
    "oth_incom = {i[0]: i[1].astype(type_of_columns_oth_incom) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfdb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним пропущенные значения в столбцах значениями предыдущей заполненной ячейки по строкам\n",
    "for i in oth_incom.values():\n",
    "    i['Организация'] = i['Организация'].fillna(method='ffill', axis=0)\n",
    "    i['Счет'] = i['Счет'].fillna(method='ffill', axis=0)\n",
    "    i['Кор_счет'] = i['Кор_счет'].fillna(method='ffill', axis=0)\n",
    "    i['Вид статьи'] = i['Вид статьи'].fillna(method='ffill', axis=0)\n",
    "    i['Статья'] = i['Статья'].fillna(method='ffill', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fa840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i.dropna(subset=['Дата'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3688c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_formats = ['%d.%m.%Y', '%m/%d/%Y'] # форматы дат\n",
    "# преобразуем строки в даты, используя один из форматов\n",
    "for i in oth_incom.values():\n",
    "    i['Дата'] = i['Дата'].apply(lambda row: pd.to_datetime(row, format=next((f for f in date_formats if pd.to_datetime(row, format=f, errors='coerce') is not pd.NaT), None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373aae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].drop(columns=[0, 'Кор_счет'])\n",
    "         for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исключим пустые датафреймы\n",
    "oth_incom = {i[0]: i[1] for i in oth_incom.items() if not i[1].empty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1006fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Статья'] = i['Статья'].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0510880",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].groupby(['Организация',\n",
    "                                 'Вид статьи',\n",
    "                                 'Статья',\n",
    "                                 'Дата'], as_index=False)['Изменение'].sum() for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь, где ключ - название группы компаний, а значение - список таблиц по всем компаниям группы\n",
    "oth_incom_groups = {}\n",
    "\n",
    "for key, value in oth_incom.items():\n",
    "    group = key.split('(')[1].split(')')[0]\n",
    "    if group in oth_incom_groups:\n",
    "        oth_incom_groups[group].append(value)\n",
    "    else:\n",
    "        oth_incom_groups[group] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый словарь с объединёнными таблицами\n",
    "oth_incom_merged = {f'Прочие доходы_{i[0]}.xlsx': pd.concat(i[1], axis=0).reset_index(inplace=False, drop=True)\n",
    "                    for i in oth_incom_groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим последнюю дату по всем датафреймам группы компаний, чтобы продлить датафреймы с более ранними последними датами до самой поздней даты\n",
    "last_date = {i[0]: i[1].sort_values(by='Дата')['Дата'].iloc[-1] for i in oth_incom_merged.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь со строками на последнюю дату из статей, которые нужно продлить\n",
    "oth_incom_new_rows = {i[0]: i[1].groupby(['Организация', 'Вид статьи', 'Статья'], as_index=False)['Дата'].max() for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим статьи, которые не нужно продлять\n",
    "for i in oth_incom_new_rows.items():\n",
    "    i[1].drop(i[1][i[1]['Дата'] == last_date[f'Прочие доходы_{i[0].split(\"(\")[1].split(\")\")[0]}.xlsx']].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменим добавляемые строки\n",
    "for i in oth_incom_new_rows.items():\n",
    "    i[1]['Изменение'] = 0\n",
    "    i[1]['Дата'] = last_date[f'Прочие доходы_{i[0].split(\"(\")[1].split(\")\")[0]}.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe376ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим новые строки в датафреймы\n",
    "oth_incom = {i[0]: pd.concat([i[1], oth_incom_new_rows[i[0]]]) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de4d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим столбцы для добавления новых данных по остаткам на счетах\n",
    "for i in oth_incom.values():\n",
    "    i['Разница'] = i.groupby(['Организация', 'Вид статьи', 'Статья'])['Дата'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09143648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим промежуточные значения по остаткам на счёте, используя диапазоны дат\n",
    "for i in oth_incom.values():\n",
    "    i['Начальная дата'] = i['Дата'] - i['Разница'] + timedelta(days=1)\n",
    "    i['Конечная дата'] = i['Дата']\n",
    "    i['Дата'] = i.apply(lambda row: pd.date_range(start=row['Начальная дата'],\n",
    "                                                  end=row['Конечная дата']).tolist()\n",
    "                        if pd.notna(row['Начальная дата'])\n",
    "                        else row['Дата'],\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6164425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим новые строки с датами\n",
    "oth_incom = {i[0]: i[1].explode('Дата') for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Изменение'] = i.apply(lambda row: 0 if row['Дата'] != row['Конечная дата'] else row['Изменение'],\n",
    "                             axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c381ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].drop(columns=['Разница',\n",
    "                                      'Начальная дата',\n",
    "                                      'Конечная дата'])\n",
    "             for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь для добавления промежуточных значений по остаткам на счетах, используя данные по остаткам на дату накопительным итогом\n",
    "# сгруппируем до уровня дат и получим уникальные значения статей для каждой даты\n",
    "oth_incom_values = {i[0]: i[1].groupby(['Организация', 'Вид статьи', 'Дата'], as_index=False)['Статья'].unique() for i in oth_incom.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отсортируем датафреймы по дате\n",
    "oth_incom_values = {i[0]: i[1].groupby(['Организация', 'Вид статьи'], as_index=False).apply(lambda row: row.sort_values('Дата')) for i in oth_incom_values.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fe849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# присвоим индексы\n",
    "oth_incom_values = {i[0]: i[1].groupby(['Организация', 'Вид статьи'], as_index=False).apply(lambda row: row.reset_index(drop=True)) for i in oth_incom_values.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244262d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим на каждую дату список из списков уникальных статей накопительным итогом\n",
    "grouped_dict = {}\n",
    "for key, value in oth_incom_values.items():\n",
    "    group_list = []\n",
    "    for name, group in value.groupby(level=0):\n",
    "        group['Статья (доп)'] = group.index.map(lambda row: group.loc[:row, 'Статья'].tolist())\n",
    "        group['Статья (доп)'] = group['Статья (доп)'].apply(lambda row: set([x for sublist in row for x in sublist]))\n",
    "        group_list.append(group)\n",
    "    table = pd.concat(group_list, axis=0)\n",
    "    grouped_dict[key] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223161e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom_values = grouped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cac4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим новые строки со статьями\n",
    "oth_incom_values = {i[0]: i[1].explode('Статья (доп)') for i in oth_incom_values.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae43798",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom_values.values():\n",
    "    i['Статья'] = i['Статья (доп)']\n",
    "    i['Изменение'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8829c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom_values = {i[0]: i[1].drop(columns=['Статья (доп)'])\n",
    "                    for i in oth_incom_values.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47262556",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: pd.concat([i[1], oth_incom_values[i[0]]]) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ffa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].sort_values(by='Дата').groupby(['Организация',\n",
    "                                                        'Вид статьи',\n",
    "                                                        'Статья',\n",
    "                                                        'Дата'],\n",
    "                                                       as_index=False)['Изменение'].sum() for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Начальный остаток'] = 0.0\n",
    "    i['Конечный остаток'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новые таблицы для расчёта остатков\n",
    "oth_incom_grouped = {i[0]: i[1].sort_values(by='Дата').groupby(['Организация',\n",
    "                                                                'Вид статьи',\n",
    "                                                                'Статья',\n",
    "                                                                'Дата'],\n",
    "                                                               as_index=False)['Изменение'].sum() for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ceda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dict = {}\n",
    "for key, value in oth_incom_grouped.items():\n",
    "    # применение операций shift и cumsum к каждому счёту, организации и виду статьи отдельно\n",
    "    group_list = []\n",
    "    for name, group in value.groupby(['Организация',\n",
    "                                      'Вид статьи',\n",
    "                                      'Статья']):\n",
    "        group['Начальный остаток'] = group['Изменение'].shift(fill_value=0).cumsum()\n",
    "        group['Конечный остаток'] = group['Начальный остаток'] + group['Изменение']\n",
    "        group_list.append(group)\n",
    "    table = pd.concat(group_list, axis=0)\n",
    "    grouped_dict[key] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom_grouped = grouped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = {}\n",
    "# объединим словарь с таблицами для расчёта остатков\n",
    "for key, table1 in oth_incom.items():\n",
    "    table2 = oth_incom_grouped.get(key)\n",
    "    merged_table = pd.merge(table1, table2, on=['Организация',\n",
    "                                                'Вид статьи',\n",
    "                                                'Статья',\n",
    "                                                'Дата'],\n",
    "                            how='left',\n",
    "                            suffixes=('', '_new'))\n",
    "    merged_dict[key] = merged_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fd83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Начальный остаток'] = i['Начальный остаток_new']\n",
    "    i['Конечный остаток'] = i['Конечный остаток_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим лишние столбцы\n",
    "oth_incom = {i[0]: i[1].iloc[:, :-3] for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c94e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom.values():\n",
    "    i['Показатель'] = 'Прочие доходы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oth_incom = {i[0]: i[1].reset_index(drop=True) for i in oth_incom.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618849d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь, где ключ - название группы компаний, а значение - список таблиц по всем компаниям группы\n",
    "oth_incom_groups = {}\n",
    "\n",
    "for key, value in oth_incom.items():\n",
    "    group = key.split('(')[1].split(')')[0]\n",
    "    if group in oth_incom_groups:\n",
    "        oth_incom_groups[group].append(value)\n",
    "    else:\n",
    "        oth_incom_groups[group] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7789117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый словарь с объединёнными таблицами\n",
    "oth_incom_merged = {f'Прочие доходы_{i[0]}.xlsx': pd.concat(i[1], axis=0).reset_index(inplace=False, drop=True)\n",
    "                    for i in oth_incom_groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ef7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in oth_incom_merged.items():\n",
    "    print(f'{i[0]}:')\n",
    "    print(i[1].info(show_counts=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c158532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим исходные данные с расширением .xlsx из первоначальной папки\n",
    "for i in source_oth_incom_name:\n",
    "    os.remove(os.path.join(source, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
